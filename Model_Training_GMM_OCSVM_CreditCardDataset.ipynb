{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11f809-1bd4-43c4-9135-4b9ab08a47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22eecd2",
   "metadata": {},
   "source": [
    "## 1- Load Credit Card Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed49e48-7574-4194-8f92-ee22b62d39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read Credit Card Data\n",
    "cc_df = pd.read_csv(\"outputs/credit_card_PCA.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46168a53-5223-48fd-a0a6-b308594d01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Inspect the first few rows to verify column names:\n",
    "print(cc_df.head())\n",
    "print(cc_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456512f",
   "metadata": {},
   "source": [
    "## 2- Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b3bd5-9a3c-4a90-99b4-54e5a1a841c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split into feature matrix X_cc and target vector y_cc.\n",
    "#    We drop the 'Class' column from X; y_cc holds 0 (normal) / 1 (fraud).\n",
    "X_cc = cc_df.drop(columns=['Class'])\n",
    "y_cc = cc_df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee6c55-a164-4897-aca1-f2e4d65ea38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Quick sanity check: shapes and class distribution\n",
    "print(\"=== Credit Card Dataset ===\")\n",
    "print(\"X_cc shape:\", X_cc.shape)\n",
    "print(\"y_cc class distribution:\\n\", y_cc.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a951e4",
   "metadata": {},
   "source": [
    "## 3- Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402843b3-9f98-45bf-a312-88ae67dc06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use StratifiedKFold to keep class imbalance roughly equal across folds.\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "repeats = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c0bf7-2be5-446b-95fc-accd2a17df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare empty dictionaries to collect (AUC, AUPRC) for each method and scenario.\n",
    "results_cc = {\n",
    "    'majority': {\n",
    "        'OCSVM': [],\n",
    "        'OCSVM_Sigmoid': [],\n",
    "        'OCSVM_Isotonic': [],\n",
    "        'GMM': [],\n",
    "        'GMM_Sigmoid': []\n",
    "    },\n",
    "    'minority': {\n",
    "        'OCSVM': [],\n",
    "        'OCSVM_Sigmoid': [],\n",
    "        'OCSVM_Isotonic': [],\n",
    "        'GMM': [],\n",
    "        'GMM_Sigmoid': []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f169f",
   "metadata": {},
   "source": [
    "## 4- Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7881ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def calibrate_scores(scores, y_true, method=\"sigmoid\"):\n",
    "    if method == \"sigmoid\":\n",
    "        calibrator = LogisticRegression(solver=\"lbfgs\")\n",
    "    elif method == \"isotonic\":\n",
    "        calibrator = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    else:\n",
    "        raise ValueError(\"Unknown calibration method.\")\n",
    "\n",
    "    calibrator.fit(scores.reshape(-1, 1), y_true)\n",
    "    return calibrator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d024e7",
   "metadata": {},
   "source": [
    "## 5- Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f82720-4ceb-40a9-bf8e-1b9cb631be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDIT CARD: MAJORITY (Only Normal) VS MINORITY (Only Fraud) TRAINING\n",
    "\n",
    "for r in range(repeats):\n",
    "    print(f\"\\n--- Credit Card: Repeat {r+1}/{repeats} ---\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_cc, y_cc), start=1):\n",
    "        \n",
    "        # Split feature matrix and target into training and testing sets for this fold.\n",
    "        X_train, X_test = X_cc.values[train_idx], X_cc.values[test_idx]\n",
    "        y_train, y_test = y_cc.values[train_idx], y_cc.values[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------------------------\n",
    "        # 1) Majority training: use only normal (y_train == 0)\n",
    "        # ---------------------------------\n",
    "        X_train_major = X_train[y_train == 0]  # All “normal” transactions\n",
    "\n",
    "\n",
    "\n",
    "        # 1st Model\n",
    "        # -- One-Class SVM (Majority) --\n",
    "        ocsvm_major_m = OneClassSVM(kernel=\"rbf\", nu=0.01, gamma=\"scale\")\n",
    "        print(\"training is started!\")\n",
    "        ocsvm_major_m.fit(X_train)\n",
    "\n",
    "\n",
    "        # Get anomaly scores\n",
    "        svm_scores_raw = ocsvm_major_m.decision_function(X_test)\n",
    "        svm_anomaly = -svm_scores_raw\n",
    "\n",
    "        # Calibrate\n",
    "        calibrator_sigmoid = calibrate_scores(svm_anomaly, y_test, method=\"sigmoid\")\n",
    "        calibrator_isotonic = calibrate_scores(svm_anomaly, y_test, method=\"isotonic\")\n",
    "\n",
    "        # Get calibrated probabilities\n",
    "        prob_sigmoid = calibrator_sigmoid.predict_proba(svm_anomaly.reshape(-1, 1))[:, 1] if hasattr(calibrator_sigmoid, \"predict_proba\") else calibrator_sigmoid.predict(svm_anomaly.reshape(-1, 1))\n",
    "        prob_isotonic = calibrator_isotonic.predict(svm_anomaly.reshape(-1, 1))\n",
    "\n",
    "        # Evaluate\n",
    "        auc_sigmoid = roc_auc_score(y_test, prob_sigmoid)\n",
    "        aupr_sigmoid = average_precision_score(y_test, prob_sigmoid)\n",
    "        auc_isotonic = roc_auc_score(y_test, prob_isotonic)\n",
    "        aupr_isotonic = average_precision_score(y_test, prob_isotonic)\n",
    "\n",
    "        results_cc['majority']['OCSVM_Sigmoid'].append((auc_sigmoid, aupr_sigmoid))\n",
    "        results_cc['majority']['OCSVM_Isotonic'].append((auc_isotonic, aupr_isotonic))\n",
    "\n",
    "        print(f\"Majority OCSVM + Sigmoid: AUC={auc_sigmoid:.4f}, AUPR={aupr_sigmoid:.4f}\")\n",
    "        print(f\"Majority OCSVM + Isotonic: AUC={auc_isotonic:.4f}, AUPR={aupr_isotonic:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # 2nd Model\n",
    "        # -- One-Class GMM (Majority) --\n",
    "        gmm_major = GaussianMixture(n_components=1, random_state=42)\n",
    "        gmm_major.fit(X_train_major)\n",
    "\n",
    "\n",
    "        # Get raw scores and convert to anomaly scores\n",
    "        gmm_scores_raw_major_gmm = gmm_major.score_samples(X_test)\n",
    "        gmm_anomaly_major_gmm = -gmm_scores_raw_major_gmm\n",
    "\n",
    "        # Calibrate using sigmoid and isotonic\n",
    "        calibrator_sigmoid_major_gmm = calibrate_scores(gmm_anomaly_major_gmm, y_test, method=\"sigmoid\")\n",
    "        # calibrator_isotonic_major_gmm = calibrate_scores(gmm_anomaly_major_gmm, y_test_m, method=\"isotonic\")\n",
    "\n",
    "        # Get calibrated probabilities\n",
    "        prob_sigmoid_major_gmm = (\n",
    "            calibrator_sigmoid_major_gmm.predict_proba(gmm_anomaly_major_gmm.reshape(-1, 1))[:, 1]\n",
    "            if hasattr(calibrator_sigmoid_major_gmm, \"predict_proba\")\n",
    "            else calibrator_sigmoid_major_gmm.predict(gmm_anomaly_major_gmm.reshape(-1, 1))\n",
    "        )\n",
    "\n",
    "\n",
    "        # Evaluate calibrated results\n",
    "        auc_sigmoid_major_gmm = roc_auc_score(y_test, prob_sigmoid_major_gmm)\n",
    "        aupr_sigmoid_major_gmm = average_precision_score(y_test, prob_sigmoid_major_gmm)\n",
    "\n",
    "        # Save results\n",
    "        results_cc['majority']['GMM_Sigmoid'].append((auc_sigmoid_major_gmm, aupr_sigmoid_major_gmm))\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Majority GMM + Sigmoid: AUC={auc_sigmoid_major_gmm:.4f}, AUPR={aupr_sigmoid_major_gmm:.4f}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------------------------\n",
    "        # 2) Minority training: use only fraud (y_train == 1)\n",
    "        # ---------------------------------\n",
    "        X_train_minor = X_train[y_train == 1]  # All “fraud” transactions\n",
    "\n",
    "        if len(X_train_minor) > 0:\n",
    "            \n",
    "            # 1st model\n",
    "            # -- One-Class SVM (Minority) --\n",
    "            ocsvm_minor_m = OneClassSVM(kernel=\"rbf\", nu=0.01, gamma=\"scale\")\n",
    "            print(\"training is started!\")\n",
    "            ocsvm_minor_m.fit(X_train_minor)\n",
    "\n",
    "            # Get anomaly scores\n",
    "            svm_scores_raw_minor_svm = ocsvm_minor_m.decision_function(X_test)\n",
    "            svm_anomaly_minor_svm = -svm_scores_raw_minor_svm\n",
    "\n",
    "            # Calibrate\n",
    "            calibrator_sigmoid_minor_svm = calibrate_scores(svm_anomaly_minor_svm, y_test, method=\"sigmoid\")\n",
    "            calibrator_isotonic_minor_svm = calibrate_scores(svm_anomaly_minor_svm, y_test, method=\"isotonic\")\n",
    "\n",
    "            # Get calibrated probabilities\n",
    "            prob_sigmoid_minor_svm = (\n",
    "                calibrator_sigmoid_minor_svm.predict_proba(svm_anomaly_minor_svm.reshape(-1, 1))[:, 1]\n",
    "                if hasattr(calibrator_sigmoid_minor_svm, \"predict_proba\")\n",
    "                else calibrator_sigmoid_minor_svm.predict(svm_anomaly_minor_svm.reshape(-1, 1))\n",
    "            )\n",
    "\n",
    "            prob_isotonic_minor_svm = calibrator_isotonic_minor_svm.predict(svm_anomaly_minor_svm.reshape(-1, 1))\n",
    "\n",
    "            # Evaluate\n",
    "            auc_sigmoid_minor_svm = roc_auc_score(y_test, prob_sigmoid_minor_svm)\n",
    "            aupr_sigmoid_minor_svm = average_precision_score(y_test, prob_sigmoid_minor_svm)\n",
    "            auc_isotonic_minor_svm = roc_auc_score(y_test, prob_isotonic_minor_svm)\n",
    "            aupr_isotonic_minor_svm = average_precision_score(y_test, prob_isotonic_minor_svm)\n",
    "\n",
    "            # Store results\n",
    "            results_cc['minority']['OCSVM_Sigmoid'].append((auc_sigmoid_minor_svm, aupr_sigmoid_minor_svm))\n",
    "            results_cc['minority']['OCSVM_Isotonic'].append((auc_isotonic_minor_svm, aupr_isotonic_minor_svm))\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Minority OCSVM (Minority) + Sigmoid: AUC={auc_sigmoid_minor_svm:.4f}, AUPR={aupr_sigmoid_minor_svm:.4f}\")\n",
    "            print(f\"Minority OCSVM (Minority) + Isotonic: AUC={auc_isotonic_minor_svm:.4f}, AUPR={aupr_isotonic_minor_svm:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # 2nd Model\n",
    "            # -- One-Class GMM (Minority) --\n",
    "            gmm_minor_m = GaussianMixture(n_components=1, random_state=42)\n",
    "            gmm_minor_m.fit(X_train_minor)\n",
    "\n",
    "\n",
    "            # Get raw scores and convert to anomaly scores (negate log-likelihood)\n",
    "            gmm_scores_raw_minor_gmm = gmm_minor_m.score_samples(X_test)\n",
    "            gmm_anomaly_minor_gmm = -gmm_scores_raw_minor_gmm\n",
    "\n",
    "            # Calibrate using sigmoid (you can add isotonic similarly if needed)\n",
    "            calibrator_sigmoid_minor_gmm = calibrate_scores(gmm_anomaly_minor_gmm, y_test, method=\"sigmoid\")\n",
    "            \n",
    "            # Get calibrated probabilities\n",
    "            prob_sigmoid_minor_gmm = (\n",
    "                calibrator_sigmoid_minor_gmm.predict_proba(gmm_anomaly_minor_gmm.reshape(-1, 1))[:, 1]\n",
    "                if hasattr(calibrator_sigmoid_minor_gmm, \"predict_proba\")\n",
    "                else calibrator_sigmoid_minor_gmm.predict(gmm_anomaly_minor_gmm.reshape(-1, 1))\n",
    "            )\n",
    "\n",
    "            # prob_isotonic_minor_gmm = calibrator_isotonic_minor_gmm.predict(gmm_anomaly_minor_gmm.reshape(-1, 1))\n",
    "\n",
    "            # Evaluate calibrated results\n",
    "            auc_sigmoid_minor_gmm = roc_auc_score(y_test, prob_sigmoid_minor_gmm)\n",
    "            aupr_sigmoid_minor_gmm = average_precision_score(y_test, prob_sigmoid_minor_gmm)\n",
    "\n",
    "            # Save results\n",
    "            results_cc['minority']['GMM_Sigmoid'].append((auc_sigmoid_minor_gmm, aupr_sigmoid_minor_gmm))\n",
    "        \n",
    "            # Print results\n",
    "            print(f\"Minority GMM + Sigmoid: AUC={auc_sigmoid_minor_gmm:.4f}, AUPR={aupr_sigmoid_minor_gmm:.4f}\")\n",
    "            \n",
    "\n",
    "\n",
    "        else:\n",
    "            # If no fraud samples in this fold’s training split, skip minority training.\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"--- Finished Credit Card Repeat {r+1} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc0d9a",
   "metadata": {},
   "source": [
    "## 7- Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536cea4-a101-40ee-b583-f2b3e3724577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_scores(score_list):\n",
    "    \"\"\"\n",
    "    Given a list of (AUC, AUPRC) tuples, return the average AUC and AUPRC.\n",
    "    \"\"\"\n",
    "    arr = np.array(score_list)   # shape = (num_experiments, 2)\n",
    "    return arr.mean(axis=0)      # returns (mean_auc, mean_auprc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in results_cc:\n",
    "    print(f'\\n>>> {group.upper()}')\n",
    "    for method in results_cc[group]:\n",
    "        scores = results_cc[group][method]\n",
    "        if scores:\n",
    "            mean_auc, mean_aupr = compute_mean_scores(scores)\n",
    "            print(f'{method:20s} | AUC: {mean_auc:.4f} | AUPRC: {mean_aupr:.4f}')\n",
    "        else:\n",
    "            print(f'{method:20s} | No scores available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc49b6",
   "metadata": {},
   "source": [
    "## 8- ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute ROC curves for all variants\n",
    "fpr_sigmoid_minor, tpr_sigmoid_minor, _ = roc_curve(y_test, prob_sigmoid_minor_svm)\n",
    "fpr_isotonic_minor, tpr_isotonic_minor, _ = roc_curve(y_test, prob_isotonic_minor_svm)\n",
    "fpr_sigmoid_major, tpr_sigmoid_major, _ = roc_curve(y_test, prob_sigmoid)\n",
    "fpr_isotonic_major, tpr_isotonic_major, _ = roc_curve(y_test, prob_isotonic)\n",
    "\n",
    "# fpr_sigmoid_minor_gmm, tpr_sigmoid_minor_gmm, _ = roc_curve(y_test, prob_sigmoid_minor_gmm)\n",
    "# fpr_sigmoid_major_gmm, tpr_sigmoid_major_gmm, _ = roc_curve(y_test, prob_sigmoid_major_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb9455",
   "metadata": {},
   "source": [
    "### Save Pickled TPR and FPR values for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "os.makedirs(\"pickled_storage\", exist_ok=True)\n",
    "\n",
    "# Save each (fpr, tpr) pair\n",
    "with open(\"pickled_storage/fpr_sigmoid_minor_OCSVM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fpr_sigmoid_minor, f)\n",
    "with open(\"pickled_storage/tpr_sigmoid_minor_OCSVM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tpr_sigmoid_minor, f)\n",
    "with open(\"pickled_storage/fpr_isotonic_minor_OCSVM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fpr_isotonic_minor, f)\n",
    "with open(\"pickled_storage/tpr_isotonic_minor_OCSVM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tpr_isotonic_minor, f)\n",
    "\n",
    "\n",
    "with open(\"pickled_storage/fpr_sigmoid_major_OCSVM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fpr_sigmoid_major, f)\n",
    "with open(\"pickled_storage/tpr_sigmoid_major_OCSVM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tpr_sigmoid_major, f)\n",
    "with open(\"pickled_storage/fpr_isotonic_major_OCSVM.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fpr_isotonic_major, f)\n",
    "with open(\"pickled_storage/tpr_isotonic_major_OCSVM.pkl\", \"wb\")  as f:\n",
    "    pickle.dump(tpr_isotonic_major, f)\n",
    "\n",
    "\n",
    "\n",
    "with open(\"pickled_storage/fpr_sigmoid_minor_gmm.pkl\", \"rb\") as f:\n",
    "    fpr_sigmoid_minor_gmm = pickle.load(f)\n",
    "with open(\"pickled_storage/tpr_sigmoid_minor_gmm.pkl\", \"rb\") as f:\n",
    "    tpr_sigmoid_minor_gmm = pickle.load(f)\n",
    "with open(\"pickled_storage/fpr_sigmoid_major_gmm.pkl\", \"rb\") as f:\n",
    "    fpr_sigmoid_major_gmm = pickle.load(f)\n",
    "with open(\"pickled_storage/tpr_sigmoid_major_gmm.pkl\", \"rb\") as f:\n",
    "    tpr_sigmoid_major_gmm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed484cf",
   "metadata": {},
   "source": [
    "### Plot 3 model's ROC Curve in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with pickled files\n",
    "path = \"pickled_storage\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Models and calibration methods to include\n",
    "model_order = [\n",
    "    (\"GMM\", \"sigmoid\"),\n",
    "    (\"OCSVM\", \"sigmoid\"),\n",
    "    (\"OCSVM\", \"isotonic\"),\n",
    "]\n",
    "\n",
    "# Color map for model types\n",
    "colors = {\n",
    "    \"GMM\": \"#C70707\",\n",
    "    \"OCSVM + Sigmoid\": \"#121746\",\n",
    "    \"OCSVM + Isotonic\": \"#43D139\",\n",
    "}\n",
    "\n",
    "# Store curves as: (label, fpr, tpr, is_minority)\n",
    "curves = []\n",
    "\n",
    "for model, calib in model_order:\n",
    "    model_lower = model.lower()\n",
    "    calib_lower = calib.lower()\n",
    "\n",
    "    # Base label for plotting color consistency\n",
    "    base_label = model if model == \"GMM\" else f\"{model} + {calib.capitalize()}\"\n",
    "\n",
    "    # Find both majority and minority files\n",
    "    for group in [\"major\", \"minor\"]:\n",
    "        # Skip OCAN models\n",
    "        fpr_file = [f for f in files if f.startswith(f\"fpr_{calib_lower}\") and model_lower in f.lower() and group in f.lower() and \"OCAN\" not in f]\n",
    "        tpr_file = [f for f in files if f.startswith(f\"tpr_{calib_lower}\") and model_lower in f.lower() and group in f.lower() and \"OCAN\" not in f]\n",
    "\n",
    "        if fpr_file and tpr_file:\n",
    "            with open(os.path.join(path, fpr_file[0]), \"rb\") as f:\n",
    "                fpr = pickle.load(f)\n",
    "            with open(os.path.join(path, tpr_file[0]), \"rb\") as f:\n",
    "                tpr = pickle.load(f)\n",
    "\n",
    "            is_minority = \"minor\" in fpr_file[0].lower()\n",
    "            if base_label == \"GMM\":\n",
    "                updated_base_label = \"GMM + Sigmoid\"\n",
    "            else:\n",
    "                updated_base_label = base_label\n",
    "\n",
    "            label = f\"{updated_base_label} ({'Minority' if is_minority else 'Majority'})\"\n",
    "            curves.append((label, fpr, tpr, is_minority, base_label))\n",
    "        else:\n",
    "            print(f\"[Warning] Missing files for {model} {calib} {group}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for label, fpr, tpr, is_minority, base_label in curves:\n",
    "    linestyle = \"dashed\" if is_minority else \"-\"\n",
    "    color = colors[base_label]\n",
    "    plt.plot(fpr, tpr, linestyle=linestyle, color=color, label=label, linewidth=2.0)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"FPR\",fontsize=20)\n",
    "plt.ylabel(\"TPR\",fontsize=20)\n",
    "# plt.title(\"ROC Curves by Model and Class\",fontsize=14)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env_v_1_13_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
