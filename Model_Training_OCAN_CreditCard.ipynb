{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DNES6ALc3ily"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3P3Gu04J3ocZ",
    "outputId": "05adf427-7c1f-4e04-ade3-2df4094b609c"
   },
   "source": [
    "## 1- Load Credit Card Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xy-j_foS3nHg"
   },
   "outputs": [],
   "source": [
    "cc_df = pd.read_csv(\"outputs/credit_card_PCA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHdSgYPU4LlM",
    "outputId": "eb925b01-65c9-4d9f-82eb-1de37a3a8a5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nvP8ijT_4aHs"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1).values.astype(np.float32)\n",
    "y = df['Class'].values\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrJKEMcE4d9U",
    "outputId": "107e0567-0f62-4672-e350-80ff3c72f4c0"
   },
   "outputs": [],
   "source": [
    "X_cc = df.drop(columns=['Class'])\n",
    "y_cc = df['Class']\n",
    "\n",
    "# 5. Quick sanity check: shapes and class distribution\n",
    "print(\"=== Credit Card Dataset ===\")\n",
    "print(\"X_cc shape:\", X_cc.shape)\n",
    "print(\"y_cc class distribution:\\n\", y_cc.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "print(\"\\n Features shape:\", X_cc.shape)\n",
    "print(\" Target shape:\", y_cc.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8UmO-oG34xjX"
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 3. Cross-validation\n",
    "# -----------------------\n",
    "repeats = 10\n",
    "folds = 5\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "results = {\n",
    "    'majority': {'auc': [], 'aupr': []},\n",
    "    'minority': {'auc': [], 'aupr': []}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Vzt4hL7Q3ahZ"
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Generator ve Discriminator\n",
    "# --------------------------\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, z\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "# --------------------------\n",
    "# OCAN Trainer\n",
    "# --------------------------\n",
    "\n",
    "class OCAN:\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hidden_dim=64,\n",
    "                 lr_g=1e-3,\n",
    "                 lr_d=1e-3,\n",
    "                 n_epochs=20,\n",
    "                 batch_size=128, device='cpu'):\n",
    "        self.device = device\n",
    "        self.gen = Generator(input_dim, hidden_dim).to(device)\n",
    "        self.dis = Discriminator(hidden_dim // 2).to(device)\n",
    "        self.opt_g = optim.Adam(self.gen.parameters(), lr=lr_g)\n",
    "        self.opt_d = optim.Adam(self.dis.parameters(), lr=lr_d)\n",
    "        self.criterion_recon = nn.MSELoss()\n",
    "        self.criterion_adv = nn.BCELoss()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # create logs folder and open log file\n",
    "        os.makedirs(\"logs\", exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        self.log_file = f\"logs/ocan_log_{timestamp}.txt\"\n",
    "\n",
    "    def log(self, message):\n",
    "        with open(self.log_file, \"a\") as f:\n",
    "            f.write(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}\\n\")\n",
    "\n",
    "    def fit(self, X):\n",
    "        ds = TensorDataset(torch.tensor(X, dtype=torch.float32))\n",
    "        loader = DataLoader(ds, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(1, self.n_epochs + 1):\n",
    "            epoch_loss_d = 0.0\n",
    "            epoch_loss_g = 0.0\n",
    "\n",
    "            for (x_batch,) in loader:\n",
    "                x_batch = x_batch.to(self.device)\n",
    "\n",
    "                # --- Train Discriminator ---\n",
    "                with torch.no_grad():\n",
    "                    _, z_real = self.gen(x_batch)\n",
    "                z_fake = torch.randn_like(z_real).to(self.device)\n",
    "                d_real = self.dis(z_real)\n",
    "                d_fake = self.dis(z_fake)\n",
    "                loss_d = self.criterion_adv(d_real, torch.ones_like(d_real)) + \\\n",
    "                         self.criterion_adv(d_fake, torch.zeros_like(d_fake))\n",
    "                self.opt_d.zero_grad()\n",
    "                loss_d.backward()\n",
    "                self.opt_d.step()\n",
    "\n",
    "                # --- Train Generator ---\n",
    "                recon, z = self.gen(x_batch)\n",
    "                d_out = self.dis(z)\n",
    "                loss_recon = self.criterion_recon(recon, x_batch)\n",
    "                loss_g_adv = self.criterion_adv(d_out, torch.zeros_like(d_out))\n",
    "                loss_g = loss_recon + 1e-2 * loss_g_adv\n",
    "                self.opt_g.zero_grad()\n",
    "                loss_g.backward()\n",
    "                self.opt_g.step()\n",
    "\n",
    "                epoch_loss_d += loss_d.item()\n",
    "                epoch_loss_g += loss_g.item()\n",
    "\n",
    "            avg_d = epoch_loss_d / len(loader)\n",
    "            avg_g = epoch_loss_g / len(loader)\n",
    "\n",
    "            # log and print\n",
    "            self.log(f\"Epoch {epoch}/{self.n_epochs} | loss_d={avg_d:.4f} | loss_g={avg_g:.4f}\")\n",
    "            if epoch % 10 == 0 or epoch == self.n_epochs:\n",
    "                print(f\"[Epoch {epoch:3d}] loss_d={avg_d:.4f}  loss_g={avg_g:.4f}\")\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        ds = TensorDataset(torch.tensor(X, dtype=torch.float32))\n",
    "        loader = DataLoader(ds, batch_size=self.batch_size, shuffle=False)\n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "            for (x_batch,) in loader:\n",
    "                x_batch = x_batch.to(self.device)\n",
    "                recon, z = self.gen(x_batch)\n",
    "                rec_err = torch.mean((recon - x_batch) ** 2, dim=1)\n",
    "                d_out = self.dis(z).squeeze()\n",
    "                score = rec_err + d_out  # higher score → more anomalous\n",
    "                scores.append(score.cpu())\n",
    "        return torch.cat(scores).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INTT6Tuc44RN",
    "outputId": "f33aa76e-2852-41d3-9321-05a5307f9c6e"
   },
   "outputs": [],
   "source": [
    "for r in range(repeats):\n",
    "    print(f\"\\n=== REPEAT {r+1}/{repeats} ===\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        print(f\"\\n--- Fold {fold}/{folds} ---\")\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Majority training (non-fraud = 0)\n",
    "        X_train_major = X_train[y_train == 0]\n",
    "        print(\"Training OCAN on majority (non-fraud)...\")\n",
    "        ocan_major = OCAN(input_dim=X.shape[1], device=device)\n",
    "        ocan_major.fit(X_train_major)\n",
    "        scores_major = ocan_major.score_samples(X_test)\n",
    "        auc_major = roc_auc_score(y_test, scores_major)\n",
    "        aupr_major = average_precision_score(y_test, scores_major)\n",
    "        results['majority']['auc'].append(auc_major)\n",
    "        results['majority']['aupr'].append(aupr_major)\n",
    "        print(f\"Majority OCAN → AUC: {auc_major:.4f}, AUPR: {aupr_major:.4f}\")\n",
    "\n",
    "        # Minority training (fraud = 1)\n",
    "        X_train_min = X_train[y_train == 1]\n",
    "        if len(X_train_min) > 0:\n",
    "            print(\"Training OCAN on minority (fraud)...\")\n",
    "            ocan_min = OCAN(input_dim=X.shape[1], device=device)\n",
    "            ocan_min.fit(X_train_min)\n",
    "            scores_min = ocan_min.score_samples(X_test)\n",
    "            auc_min = roc_auc_score((y_test == 1).astype(int), scores_min)\n",
    "            aupr_min = average_precision_score((y_test == 1).astype(int), scores_min)\n",
    "            results['minority']['auc'].append(auc_min)\n",
    "            results['minority']['aupr'].append(aupr_min)\n",
    "            print(f\"Minority OCAN → AUC: {auc_min:.4f}, AUPR: {aupr_min:.4f}\")\n",
    "        else:\n",
    "            print(\"No minority samples to train on.\")\n",
    "\n",
    "# -----------------------\n",
    "# 4. Final Results\n",
    "# -----------------------\n",
    "print(\"\\n===== FINAL RESULTS =====\")\n",
    "print(f\"Majority OCAN Mean AUC:  {np.mean(results['majority']['auc']):.4f}\")\n",
    "print(f\"Majority OCAN Mean AUPR: {np.mean(results['majority']['aupr']):.4f}\")\n",
    "print(f\"Minority OCAN Mean AUC:  {np.mean(results['minority']['auc']):.4f}\")\n",
    "print(f\"Minority OCAN Mean AUPR: {np.mean(results['minority']['aupr']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edZOLExjliV0",
    "outputId": "ba477156-a467-40b9-aeab-cd184b134c6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8862528254674165)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results['minority']['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6h5R-2xfllkd",
    "outputId": "0f6571a1-2173-4e5a-d42c-697f8ea92c01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9061039116018754)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results['majority']['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-7o79zHlftd",
    "outputId": "f121d664-97ef-4619-a30d-c9008dedb5e7"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "V_AOinaZ566C",
    "outputId": "86e1a92e-e039-45d5-9db1-17efeabe3a6a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute ROC curves for both models\n",
    "fpr_sigmoid_minor_gmm, tpr_sigmoid_minor_gmm, _ = roc_curve(y_test, scores_major)\n",
    "fpr_sigmoid_major_gmm, tpr_sigmoid_major_gmm, _ = roc_curve(y_test, scores_major)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(fpr_sigmoid_minor_gmm, tpr_sigmoid_minor_gmm,\n",
    "         label=f\"Minority OCAN (AUC = {np.mean(results['minority']['auc']):.4f})\", linestyle='-')\n",
    "\n",
    "plt.plot(fpr_sigmoid_major_gmm, tpr_sigmoid_major_gmm,\n",
    "         label=f\"Majority OCAN (AUC = {np.mean(results['majority']['auc']):.4f})\", linestyle='--')\n",
    "\n",
    "# Random baseline\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "\n",
    "# Labels and styling\n",
    "plt.title(\"ROC Curves - OCAN (Minority vs Majority)\", fontsize=14)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Pickled TPR and FPR values for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Dey-Z80MRjM9"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"pickled_storage\", exist_ok=True)\n",
    "\n",
    "# Save minority GMM ROC variables\n",
    "with open(\"pickled_storage/fpr_sigmoid_minor_OCAN.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fpr_sigmoid_minor_gmm, f)\n",
    "\n",
    "with open(\"pickled_storage/tpr_sigmoid_minor_OCAN.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tpr_sigmoid_minor_gmm, f)\n",
    "\n",
    "# Save majority GMM ROC variables\n",
    "with open(\"pickled_storage/fpr_sigmoid_major_OCAN.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fpr_sigmoid_major_gmm, f)\n",
    "\n",
    "with open(\"pickled_storage/tpr_sigmoid_major_OCAN.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tpr_sigmoid_major_gmm, f)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
